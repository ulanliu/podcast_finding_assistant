{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c0f110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e43c97fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ground_truth(df, output_file='podcast_ground_truth.json', api_key=None, max_episodes=None, sample_random=False):\n",
    "    \"\"\"\n",
    "    Generate ground truth data for podcast episodes using GPT API.\n",
    "    \n",
    "    Args:\n",
    "        df: Pandas DataFrame containing podcast episode data with 'episode', 'title', and 'summary' columns\n",
    "        output_file: Path to save the ground truth data as JSON\n",
    "        api_key: OpenAI API key (will use environment variable if None)\n",
    "        max_episodes: Maximum number of episodes to process (useful for testing with fewer episodes)\n",
    "        sample_random: If True and max_episodes is set, randomly sample episodes instead of taking first few\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing ground truth data\n",
    "    \"\"\"\n",
    "    # Initialize OpenAI client\n",
    "    if api_key is None:\n",
    "        api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "        if api_key is None:\n",
    "            raise ValueError(\"OpenAI API key not found. Please provide it as an argument or set the OPENAI_API_KEY environment variable.\")\n",
    "    \n",
    "    client = OpenAI(api_key=api_key)\n",
    "    \n",
    "    system_prompt = \"\"\"你是一位知道台灣Podcast「通勤第一品牌」(Commute For Me)的聽眾，熟悉台灣文化和用語。\n",
    "你將獲得「通勤第一品牌」(Commute For Me) podcast的標題和內容摘要。\n",
    "你的任務是：\n",
    "1. 識別該集節目中討論的15個關鍵主題\n",
    "2. 扮演只記得部分內容的聽眾，且不知道確切集數\n",
    "3. 根據第1點與第2點，寫出4個搜尋關鍵詞與1個關鍵句子(名詞+動詞)，總共5個\n",
    "4. 搜尋關鍵詞避免只出現\"家倫\"、\"李毅誠\"\n",
    "\n",
    "輸出格式應為有效的JSON，格式如下：\n",
    "'word': [\"word1\", \"word2\", ..., \"word5\"]\n",
    "\"\"\"\n",
    "\n",
    "    # Process each episode\n",
    "    ground_truth = {}\n",
    "    \n",
    "    # Limit the number of episodes if specified\n",
    "    if max_episodes is not None:\n",
    "        if sample_random:\n",
    "            df_to_process = df.sample(min(max_episodes, len(df)))\n",
    "        else:\n",
    "            df_to_process = df.head(max_episodes)\n",
    "        print(f\"Testing with {len(df_to_process)} episodes out of {len(df)} total episodes\")\n",
    "    else:\n",
    "        df_to_process = df\n",
    "    \n",
    "    for _, row in tqdm(df_to_process.iterrows(), total=len(df_to_process), desc=\"Processing episodes\"):\n",
    "        episode_id = row['episode']\n",
    "        title = row['title']\n",
    "        summary = row['summary']\n",
    "        \n",
    "        # Skip if summary is NaN\n",
    "        if pd.isna(summary):\n",
    "            print(f\"Skipping episode {episode_id} - No summary available\")\n",
    "            continue\n",
    "            \n",
    "        # Create user prompt for this episode\n",
    "        user_prompt = f\"Episode {episode_id}: {title}\\n\\nSummary:\\n{summary}\"\n",
    "        \n",
    "        # Call OpenAI API with retry mechanism for rate limits\n",
    "        max_retries = 3\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"gpt-4o-mini\",  # Using GPT-4o-mini as requested\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": system_prompt},\n",
    "                        {\"role\": \"user\", \"content\": user_prompt}\n",
    "                    ],\n",
    "                    temperature=0.2,  # Lower temperature for more consistent outputs\n",
    "                    response_format={\"type\": \"json_object\"}\n",
    "                )\n",
    "                \n",
    "                # Extract and parse JSON response\n",
    "                response_text = response.choices[0].message.content\n",
    "                episode_data = json.loads(response_text)\n",
    "                \n",
    "                # Ensure sentence field exists (for backward compatibility)\n",
    "                if \"word\" not in episode_data:\n",
    "                    episode_data[\"word\"] = []\n",
    "                \n",
    "                # Store in ground truth dictionary\n",
    "                ground_truth[str(episode_id)] = episode_data\n",
    "                \n",
    "                # Save intermediate results periodically\n",
    "                if episode_id % 10 == 0:\n",
    "                    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(ground_truth, f, ensure_ascii=False, indent=2)\n",
    "                \n",
    "                # Successful response, break out of retry loop\n",
    "                break\n",
    "                \n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error: Invalid JSON response for episode {episode_id}. Retrying...\")\n",
    "                time.sleep(2)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing episode {episode_id}: {str(e)}\")\n",
    "                if \"rate limit\" in str(e).lower():\n",
    "                    wait_time = (attempt + 1) * 5  # Exponential backoff\n",
    "                    print(f\"Rate limited. Waiting {wait_time} seconds before retry...\")\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    break  # Break on non-rate-limit errors\n",
    "        \n",
    "        # Add a small delay between requests to avoid rate limits\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    # Save final results\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(ground_truth, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"Ground truth data generated and saved to {output_file}\")\n",
    "    return ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4266c0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with 3 episodes out of 444 total episodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:05<00:00,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth data generated and saved to podcast_ground_truth.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('podcast_data.csv')\n",
    "    \n",
    "# Generate ground truth (using environment variable for API key)\n",
    "ground_truth = generate_ground_truth(df, max_episodes=3, sample_random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14187285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'57': {'word': ['成人之美', '情感回顧', '分手經驗', '友誼名片', '日本咖啡罐']},\n",
       " '215': {'word': ['國際視野', '葉耀元', '台灣研究', '教育制度', '考試制度']},\n",
       " '202': {'word': ['春困', '嗜睡症', '托嬰中心', '超商遊戲', '確診']}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f1c782b-1337-4302-ad6f-f93b072ff506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:   1%|██                                                                                                                                                                                  | 5/444 [00:08<13:10,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 6 - No summary available\n",
      "Skipping episode 7 - No summary available\n",
      "Skipping episode 8 - No summary available\n",
      "Skipping episode 9 - No summary available\n",
      "Skipping episode 10 - No summary available\n",
      "Skipping episode 11 - No summary available\n",
      "Skipping episode 12 - No summary available\n",
      "Skipping episode 13 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  14%|█████████████████████████▍                                                                                                                                                         | 63/444 [01:44<10:48,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 64 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  33%|██████████████████████████████████████████████████████████▏                                                                                                                       | 145/444 [04:22<09:43,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 146 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  50%|████████████████████████████████████████████████████████████████████████████████████████▌                                                                                         | 221/444 [06:52<06:23,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 222 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  51%|██████████████████████████████████████████████████████████████████████████████████████████▏                                                                                       | 225/444 [06:57<05:31,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 226 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  51%|███████████████████████████████████████████████████████████████████████████████████████████▍                                                                                      | 228/444 [07:01<04:46,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 229 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  56%|████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                             | 250/444 [07:40<06:10,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 251 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                         | 262/444 [07:58<04:56,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 263 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                      | 268/444 [08:07<04:51,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 269 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  61%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                     | 270/444 [08:09<03:40,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 271 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                   | 275/444 [08:16<04:30,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 276 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  64%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                | 283/444 [08:29<04:43,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 284 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                         | 300/444 [08:59<05:08,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 301 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                 | 320/444 [09:38<07:05,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 321 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                               | 325/444 [09:45<04:10,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 326 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                 | 361/444 [10:44<02:33,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 362 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  82%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                | 364/444 [10:48<02:00,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 365 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                           | 375/444 [11:05<01:52,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 376 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                       | 385/444 [11:21<01:42,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 386 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                 | 400/444 [11:45<01:10,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 401 - No summary available\n",
      "Skipping episode 402 - No summary available\n",
      "Skipping episode 403 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                | 404/444 [11:46<00:33,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 405 - No summary available\n",
      "Skipping episode 406 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏              | 407/444 [11:48<00:27,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 408 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏| 442/444 [12:51<00:03,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 443 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 444/444 [12:53<00:00,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth data generated and saved to podcast_ground_truth.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ground_truth = generate_ground_truth(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27a9673f-0248-41c1-aa78-d9d0398bae9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': ['真粉定義', '網路文化', '彩蛋解析', '深度討論', '社群反應']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth['410']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4a1ba79-2c24-40eb-8c65-00e7b945fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_topic(df, output_file='podcast_topic.json', api_key=None, max_episodes=None, sample_random=False):\n",
    "    \"\"\"\n",
    "    \n",
    "    Args:\n",
    "        df: Pandas DataFrame containing podcast episode data with 'episode', 'title', and 'summary' columns\n",
    "        output_file: Path to save the ground truth data as JSON\n",
    "        api_key: OpenAI API key (will use environment variable if None)\n",
    "        max_episodes: Maximum number of episodes to process (useful for testing with fewer episodes)\n",
    "        sample_random: If True and max_episodes is set, randomly sample episodes instead of taking first few\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing ground truth data\n",
    "    \"\"\"\n",
    "    # Initialize OpenAI client\n",
    "    if api_key is None:\n",
    "        api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "        if api_key is None:\n",
    "            raise ValueError(\"OpenAI API key not found. Please provide it as an argument or set the OPENAI_API_KEY environment variable.\")\n",
    "    \n",
    "    client = OpenAI(api_key=api_key)\n",
    "    \n",
    "    system_prompt = \"\"\"你是一位知道台灣Podcast「通勤第一品牌」(Commute For Me)的聽眾，熟悉台灣文化和用語。\n",
    "你將獲得「通勤第一品牌」(Commute For Me) podcast的標題和內容摘要。\n",
    "你的任務是：\n",
    "1. 識別該集節目中討論的10~20個關鍵主題或句子\n",
    "\n",
    "輸出格式應為有效的JSON，格式如下：\n",
    "'topic': [\"topic1\", \"topic2\", ..., \"topic20\"]\n",
    "\"\"\"\n",
    "\n",
    "    # Process each episode\n",
    "    podcast_topic = {}\n",
    "    \n",
    "    # Limit the number of episodes if specified\n",
    "    if max_episodes is not None:\n",
    "        if sample_random:\n",
    "            df_to_process = df.sample(min(max_episodes, len(df)))\n",
    "        else:\n",
    "            df_to_process = df.head(max_episodes)\n",
    "        print(f\"Testing with {len(df_to_process)} episodes out of {len(df)} total episodes\")\n",
    "    else:\n",
    "        df_to_process = df\n",
    "    \n",
    "    for _, row in tqdm(df_to_process.iterrows(), total=len(df_to_process), desc=\"Processing episodes\"):\n",
    "        episode_id = row['episode']\n",
    "        title = row['title']\n",
    "        summary = row['summary']\n",
    "        if pd.isnull(row['song_recommendation']):\n",
    "            song = 'null'\n",
    "        else:\n",
    "            song = row['song_recommendation']\n",
    "        \n",
    "        # Skip if summary is NaN\n",
    "        if pd.isna(summary):\n",
    "            print(f\"Skipping episode {episode_id} - No summary available\")\n",
    "            continue\n",
    "            \n",
    "        # Create user prompt for this episode\n",
    "        user_prompt = f\"Episode {episode_id}: {title}\\n\\nSummary:\\n{summary}\"\n",
    "        \n",
    "        # Call OpenAI API with retry mechanism for rate limits\n",
    "        max_retries = 3\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"gpt-4o-mini\",  # Using GPT-4o-mini as requested\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": system_prompt},\n",
    "                        {\"role\": \"user\", \"content\": user_prompt}\n",
    "                    ],\n",
    "                    temperature=0.2,  # Lower temperature for more consistent outputs\n",
    "                    response_format={\"type\": \"json_object\"}\n",
    "                )\n",
    "                \n",
    "                # Extract and parse JSON response\n",
    "                response_text = response.choices[0].message.content\n",
    "                episode_data = json.loads(response_text)\n",
    "                \n",
    "                # Ensure sentence field exists (for backward compatibility)\n",
    "                if \"topic\" not in episode_data:\n",
    "                    episode_data[\"topic\"] = []\n",
    "\n",
    "                episode_data[\"song\"] = song\n",
    "                \n",
    "                # Store in ground truth dictionary\n",
    "                podcast_topic[str(episode_id)] = episode_data\n",
    "                \n",
    "                # Save intermediate results periodically\n",
    "                if episode_id % 10 == 0:\n",
    "                    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(podcast_topic, f, ensure_ascii=False, indent=2)\n",
    "                \n",
    "                # Successful response, break out of retry loop\n",
    "                break\n",
    "                \n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error: Invalid JSON response for episode {episode_id}. Retrying...\")\n",
    "                time.sleep(2)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing episode {episode_id}: {str(e)}\")\n",
    "                if \"rate limit\" in str(e).lower():\n",
    "                    wait_time = (attempt + 1) * 5  # Exponential backoff\n",
    "                    print(f\"Rate limited. Waiting {wait_time} seconds before retry...\")\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    break  # Break on non-rate-limit errors\n",
    "        \n",
    "        # Add a small delay between requests to avoid rate limits\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    # Save final results\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(podcast_topic, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"Process data generated and saved to {output_file}\")\n",
    "    return podcast_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d03bce8-9175-4890-87b7-4926f91b7a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with 3 episodes out of 444 total episodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes: 100%|████████████████████████████████████████████████████| 3/3 [00:11<00:00,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process data generated and saved to podcast_topic.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('podcast_data.csv')\n",
    "    \n",
    "# Generate ground truth (using environment variable for API key)\n",
    "podcast_topic = generate_topic(df, max_episodes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d7ac0ff-6aef-4c96-9cfb-7fa441f57590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'topic': ['NMSL的起源',\n",
       "   'CS遊戲文化',\n",
       "   '丹麥二線玩家',\n",
       "   'envy團體',\n",
       "   'NMSL的含義',\n",
       "   '刺青文化',\n",
       "   '中泰twitter大戰',\n",
       "   '避敏感詞的用法',\n",
       "   '台灣的委婉表達',\n",
       "   '吳淑珍的網路搜尋',\n",
       "   '馬鶴凌的提及',\n",
       "   '人類集體淺意識',\n",
       "   '文字獄的討論',\n",
       "   '5000年的傳統',\n",
       "   '白色恐怖的歷史',\n",
       "   '誠誠的遊戲名字',\n",
       "   '手肘走路的練習',\n",
       "   '社會政治的隱喻',\n",
       "   '文化認同的探討'],\n",
       "  'song': nan},\n",
       " '2': {'topic': ['多人運動',\n",
       "   '偷情',\n",
       "   'VR做愛',\n",
       "   '通姦罪',\n",
       "   '公投',\n",
       "   '性成癮',\n",
       "   '開放性關係',\n",
       "   '羞辱感',\n",
       "   '身心分離派',\n",
       "   '空幹影片',\n",
       "   '母系社會',\n",
       "   '出軌外遇',\n",
       "   '應變能力',\n",
       "   '誠實應對',\n",
       "   '名人稅',\n",
       "   '林俊傑',\n",
       "   '台獨',\n",
       "   '羅志祥',\n",
       "   '柯粉',\n",
       "   '和解'],\n",
       "  'song': nan},\n",
       " '3': {'topic': ['清大人社學費爭論',\n",
       "   '宿舍費不退',\n",
       "   '綽號文化',\n",
       "   '條直性格',\n",
       "   '自我介紹方式',\n",
       "   '連戰的父親身份',\n",
       "   '綽號的創造與使用',\n",
       "   '李敖語錄',\n",
       "   '家庭暴力話題',\n",
       "   '性騷擾事件',\n",
       "   '社交壓力',\n",
       "   '父母對工作升遷的影響',\n",
       "   '支持民眾黨',\n",
       "   '西瓜挑戰',\n",
       "   '家庭背景與努力的關係',\n",
       "   '搞笑的原則',\n",
       "   '社會期待與個人努力',\n",
       "   '韓流影響政治',\n",
       "   '印象管理'],\n",
       "  'song': nan}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "podcast_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd2e2b8c-72b9-498b-af3d-227da93d73e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with 5 episodes out of 444 total episodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes: 100%|████████████████████████████████████████████████████| 5/5 [00:18<00:00,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process data generated and saved to podcast_topic.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "podcast_topic = generate_topic(df, max_episodes=5, sample_random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c5bbe03-580f-4e32-9228-e9cda1aa7bde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'203': {'topic': ['威滅的廣告劇',\n",
       "   '何ㄟ女友和維力炸醬麵',\n",
       "   '泡麵冷暴力',\n",
       "   '咖啡盤子的用途',\n",
       "   '奶茶機的回憶',\n",
       "   '台大學習的理論',\n",
       "   '整鰭器的使用',\n",
       "   '電影私法爭鋒',\n",
       "   '吳斐莉代言的鞋子',\n",
       "   '電影阿凡達的評價',\n",
       "   '品味的懷疑',\n",
       "   '重看Star Trek 2009',\n",
       "   '小何的故事',\n",
       "   '網頁瀏覽器的分類',\n",
       "   '情緒管理',\n",
       "   '台裔醫師的勇氣',\n",
       "   '釣魚行為的影響',\n",
       "   '負面情緒的勾動'],\n",
       "  'song': nan},\n",
       " '281': {'topic': ['夢境',\n",
       "   '張菲',\n",
       "   '睡袍',\n",
       "   '乃哥家',\n",
       "   '採訪',\n",
       "   '打麻將',\n",
       "   '成功學',\n",
       "   '筆記',\n",
       "   '超慢跑',\n",
       "   '披薩',\n",
       "   '減肥學',\n",
       "   '減肥失敗',\n",
       "   '成功學的可信度',\n",
       "   '邊做邊吃',\n",
       "   '生活方式',\n",
       "   '幽默',\n",
       "   '文化',\n",
       "   '台灣名人',\n",
       "   '休閒活動'],\n",
       "  'song': '超時空要塞'},\n",
       " '41': {'topic': ['春艷的合作經歷',\n",
       "   '第一次拿到的報酬',\n",
       "   '黑貓宅急便的工作經歷',\n",
       "   '家庭背景與佛法信仰',\n",
       "   '冥想在監獄生活中的作用',\n",
       "   '集體意志的重要性',\n",
       "   '夜生活的享受與失控',\n",
       "   '對於他人觀點的看法',\n",
       "   '慾望的空虛',\n",
       "   '夜生活中的抓馬事件',\n",
       "   '人生的需求與想要的區分',\n",
       "   '交大八社的烤香腸',\n",
       "   '音樂與情感的連結',\n",
       "   '夜貓組的代言歌',\n",
       "   '社交與人際關係的挑戰',\n",
       "   '對於生活中發生事情的接受',\n",
       "   '倫的學習與生活態度',\n",
       "   '春艷的音樂創作背景',\n",
       "   '夜生活的社會文化影響',\n",
       "   '對於失控的恐懼與接受'],\n",
       "  'song': '/'},\n",
       " '152': {'topic': ['倫迷看治療蹄底皮膚指甲病的影片',\n",
       "   '何ㄟ開始節食',\n",
       "   '168斷食法',\n",
       "   '186斷食法',\n",
       "   '何特愛小熊軟糖',\n",
       "   '哈根達斯冰淇淋',\n",
       "   '倫是馬鈴薯狂粉',\n",
       "   '薯餅蛋吐司',\n",
       "   '早餐店傑克阿姨',\n",
       "   '誠愛吃阿英煎的荷包蛋',\n",
       "   '喜歡吃濃郁的東西',\n",
       "   '海膽',\n",
       "   '臭臭的起司',\n",
       "   '家倫飲料不管什麼時候都點正常冰',\n",
       "   '從來不點少冰',\n",
       "   '家倫健身教練',\n",
       "   '掉到地上三秒理論',\n",
       "   '複雜的慾望',\n",
       "   '執念',\n",
       "   'apple tv上買4k修復版電影',\n",
       "   '電影李安父親三部曲'],\n",
       "  'song': '鼓擊樂團——One Way Trigger'},\n",
       " '430': {'topic': ['何電腦C槽壞掉',\n",
       "   '系統碟壞掉',\n",
       "   '小影片備份',\n",
       "   '前柯主席雙關',\n",
       "   '小草列出友白KOL',\n",
       "   '台灣通勤第一品牌排名',\n",
       "   '賴清德違建',\n",
       "   '台灣言論自由',\n",
       "   '李毅誠反串',\n",
       "   '何欸聽不懂反串',\n",
       "   '隱士下鋤田文本分析',\n",
       "   '土城詩人',\n",
       "   '五言絕句創作',\n",
       "   '詞選寫炫耀',\n",
       "   '中文系期末考',\n",
       "   '老師評語進步明顯',\n",
       "   '反串識別度低',\n",
       "   '棕櫚樹發音',\n",
       "   '自詡發音',\n",
       "   '踉蹌發音'],\n",
       "  'song': \"逞誠：B'z - 今夜月の見える丘に\\n看日劇「美麗人生 (ビューティフルライフ)」，推主題曲\"}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "podcast_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76bc6d97-eeb1-4a50-86f2-c187a3a4962e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:   1%|▌                                                 | 5/444 [00:17<26:21,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 6 - No summary available\n",
      "Skipping episode 7 - No summary available\n",
      "Skipping episode 8 - No summary available\n",
      "Skipping episode 9 - No summary available\n",
      "Skipping episode 10 - No summary available\n",
      "Skipping episode 11 - No summary available\n",
      "Skipping episode 12 - No summary available\n",
      "Skipping episode 13 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  14%|██████▉                                          | 63/444 [03:57<25:34,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 64 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  33%|███████████████▋                                | 145/444 [09:25<19:37,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 146 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  50%|███████████████████████▉                        | 221/444 [14:31<13:26,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 222 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  51%|████████████████████████▎                       | 225/444 [14:42<11:51,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 226 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  51%|████████████████████████▋                       | 228/444 [14:50<10:57,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 229 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  56%|███████████████████████████                     | 250/444 [16:16<16:25,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 251 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  59%|████████████████████████████▎                   | 262/444 [16:58<11:03,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 263 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  60%|████████████████████████████▉                   | 268/444 [17:19<10:53,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 269 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  61%|█████████████████████████████▏                  | 270/444 [17:22<08:01,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 271 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  62%|█████████████████████████████▋                  | 275/444 [17:40<10:35,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 276 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  64%|██████████████████████████████▌                 | 283/444 [18:01<08:09,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 284 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  68%|████████████████████████████████▍               | 300/444 [19:11<09:51,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 301 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  72%|██████████████████████████████████▌             | 320/444 [20:24<07:28,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 321 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  73%|███████████████████████████████████▏            | 325/444 [20:41<08:12,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 326 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  81%|███████████████████████████████████████         | 361/444 [23:02<05:15,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 362 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  82%|███████████████████████████████████████▎        | 364/444 [23:07<03:36,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 365 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  84%|████████████████████████████████████████▌       | 375/444 [23:50<04:47,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 376 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  87%|█████████████████████████████████████████▌      | 385/444 [24:24<03:54,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 386 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  90%|███████████████████████████████████████████▏    | 400/444 [25:21<02:36,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 401 - No summary available\n",
      "Skipping episode 402 - No summary available\n",
      "Skipping episode 403 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  91%|███████████████████████████████████████████▋    | 404/444 [25:24<01:13,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 405 - No summary available\n",
      "Skipping episode 406 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  92%|████████████████████████████████████████████    | 407/444 [25:28<00:56,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 408 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes: 100%|███████████████████████████████████████████████▊| 442/444 [27:48<00:07,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 443 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes: 100%|████████████████████████████████████████████████| 444/444 [27:51<00:00,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process data generated and saved to podcast_topic.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "podcast_topic = generate_topic(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbd2692-a0b3-40c3-a7a9-a64362131b09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
