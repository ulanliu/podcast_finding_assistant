{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c0f110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e43c97fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ground_truth(df, output_file='podcast_ground_truth.json', api_key=None, max_episodes=None, sample_random=False):\n",
    "    \"\"\"\n",
    "    Generate ground truth data for podcast episodes using GPT API.\n",
    "    \n",
    "    Args:\n",
    "        df: Pandas DataFrame containing podcast episode data with 'episode', 'title', and 'summary' columns\n",
    "        output_file: Path to save the ground truth data as JSON\n",
    "        api_key: OpenAI API key (will use environment variable if None)\n",
    "        max_episodes: Maximum number of episodes to process (useful for testing with fewer episodes)\n",
    "        sample_random: If True and max_episodes is set, randomly sample episodes instead of taking first few\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing ground truth data\n",
    "    \"\"\"\n",
    "    # Initialize OpenAI client\n",
    "    if api_key is None:\n",
    "        api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "        if api_key is None:\n",
    "            raise ValueError(\"OpenAI API key not found. Please provide it as an argument or set the OPENAI_API_KEY environment variable.\")\n",
    "    \n",
    "    client = OpenAI(api_key=api_key)\n",
    "    \n",
    "    # Create a system prompt template in Traditional Chinese\n",
    "    system_prompt = \"\"\"你是一位精通中文的podcast分析專家，熟悉台灣文化和用語。\n",
    "你將獲得「通勤第一品牌」(Commute For Me) podcast的標題和內容摘要。\n",
    "你的任務是：\n",
    "1. 識別該集節目中討論的5-10個關鍵主題\n",
    "2. 並根據這些關鍵主題創建5個與節目內容相關的問題，這些問題可以用來搜索找到這一集\n",
    "\n",
    "輸出格式應為有效的JSON，並不要用code blocks，格式如下：\n",
    "[\"question1\", \"question2\", ..., \"question5\"]\n",
    "\"\"\"\n",
    "\n",
    "    # Process each episode\n",
    "    ground_truth = {}\n",
    "    \n",
    "    # Limit the number of episodes if specified\n",
    "    if max_episodes is not None:\n",
    "        if sample_random:\n",
    "            df_to_process = df.sample(min(max_episodes, len(df)))\n",
    "        else:\n",
    "            df_to_process = df.head(max_episodes)\n",
    "        print(f\"Testing with {len(df_to_process)} episodes out of {len(df)} total episodes\")\n",
    "    else:\n",
    "        df_to_process = df\n",
    "    \n",
    "    for _, row in tqdm(df_to_process.iterrows(), total=len(df_to_process), desc=\"Processing episodes\"):\n",
    "        episode_id = row['episode']\n",
    "        title = row['title']\n",
    "        summary = row['summary']\n",
    "        \n",
    "        # Skip if summary is NaN\n",
    "        if pd.isna(summary):\n",
    "            print(f\"Skipping episode {episode_id} - No summary available\")\n",
    "            continue\n",
    "            \n",
    "        # Create user prompt for this episode\n",
    "        user_prompt = f\"Episode {episode_id}: {title}\\n\\nSummary:\\n{summary}\"\n",
    "        \n",
    "        # Call OpenAI API with retry mechanism for rate limits\n",
    "        max_retries = 3\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"gpt-4o-mini\",  # Using GPT-4o-mini as requested\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": system_prompt},\n",
    "                        {\"role\": \"user\", \"content\": user_prompt}\n",
    "                    ],\n",
    "                    temperature=0.2,  # Lower temperature for more consistent outputs\n",
    "                    response_format={\"type\": \"json_object\"}\n",
    "                )\n",
    "                \n",
    "                # Extract and parse JSON response\n",
    "                response_text = response.choices[0].message.content\n",
    "                episode_data = json.loads(response_text)\n",
    "                \n",
    "                # Ensure questions field exists (for backward compatibility)\n",
    "                if \"questions\" not in episode_data:\n",
    "                    episode_data[\"questions\"] = []\n",
    "                \n",
    "                # Store in ground truth dictionary\n",
    "                ground_truth[str(episode_id)] = episode_data\n",
    "                \n",
    "                # Save intermediate results periodically\n",
    "                if episode_id % 10 == 0:\n",
    "                    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(ground_truth, f, ensure_ascii=False, indent=2)\n",
    "                \n",
    "                # Successful response, break out of retry loop\n",
    "                break\n",
    "                \n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error: Invalid JSON response for episode {episode_id}. Retrying...\")\n",
    "                time.sleep(2)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing episode {episode_id}: {str(e)}\")\n",
    "                if \"rate limit\" in str(e).lower():\n",
    "                    wait_time = (attempt + 1) * 5  # Exponential backoff\n",
    "                    print(f\"Rate limited. Waiting {wait_time} seconds before retry...\")\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    break  # Break on non-rate-limit errors\n",
    "        \n",
    "        # Add a small delay between requests to avoid rate limits\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    # Save final results\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(ground_truth, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"Ground truth data generated and saved to {output_file}\")\n",
    "    return ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4266c0b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "OpenAI API key not found. Please provide it as an argument or set the OPENAI_API_KEY environment variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpodcast_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Generate ground truth (using environment variable for API key)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m ground_truth \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_ground_truth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m, in \u001b[0;36mgenerate_ground_truth\u001b[0;34m(df, output_file, api_key, max_episodes, sample_random)\u001b[0m\n\u001b[1;32m     17\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI API key not found. Please provide it as an argument or set the OPENAI_API_KEY environment variable.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(api_key\u001b[38;5;241m=\u001b[39mapi_key)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Create a system prompt template in Traditional Chinese\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: OpenAI API key not found. Please provide it as an argument or set the OPENAI_API_KEY environment variable."
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('podcast_data.csv')\n",
    "    \n",
    "# Generate ground truth (using environment variable for API key)\n",
    "ground_truth = generate_ground_truth(df, max_episodes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e7442de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(os.environ.get(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ba7792a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(os.environ.get(\"HUGGINGFACE_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14187285",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
