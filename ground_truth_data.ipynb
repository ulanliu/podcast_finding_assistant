{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c0f110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e43c97fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ground_truth(df, output_file='podcast_ground_truth.json', api_key=None, max_episodes=None, sample_random=False):\n",
    "    \"\"\"\n",
    "    Generate ground truth data for podcast episodes using GPT API.\n",
    "    \n",
    "    Args:\n",
    "        df: Pandas DataFrame containing podcast episode data with 'episode', 'title', and 'summary' columns\n",
    "        output_file: Path to save the ground truth data as JSON\n",
    "        api_key: OpenAI API key (will use environment variable if None)\n",
    "        max_episodes: Maximum number of episodes to process (useful for testing with fewer episodes)\n",
    "        sample_random: If True and max_episodes is set, randomly sample episodes instead of taking first few\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing ground truth data\n",
    "    \"\"\"\n",
    "    # Initialize OpenAI client\n",
    "    if api_key is None:\n",
    "        api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "        if api_key is None:\n",
    "            raise ValueError(\"OpenAI API key not found. Please provide it as an argument or set the OPENAI_API_KEY environment variable.\")\n",
    "    \n",
    "    client = OpenAI(api_key=api_key)\n",
    "    \n",
    "    system_prompt = \"\"\"你是一位知道台灣Podcast「通勤第一品牌」(Commute For Me)的聽眾，熟悉台灣文化和用語。\n",
    "你將獲得「通勤第一品牌」(Commute For Me) podcast的標題和內容摘要。\n",
    "你的任務是：\n",
    "1. 識別該集節目中討論的10個關鍵主題\n",
    "2. 並根據這些關鍵主題創建5句描述這集的直述句\n",
    "3. 直述句以口語、接近日常的方式呈現\n",
    "\n",
    "輸出格式應為有效的JSON，格式如下：\n",
    "'sentence': [\"sentence1\", \"sentence2\", ..., \"sentence5\"]\n",
    "\"\"\"\n",
    "\n",
    "    # Process each episode\n",
    "    ground_truth = {}\n",
    "    \n",
    "    # Limit the number of episodes if specified\n",
    "    if max_episodes is not None:\n",
    "        if sample_random:\n",
    "            df_to_process = df.sample(min(max_episodes, len(df)))\n",
    "        else:\n",
    "            df_to_process = df.head(max_episodes)\n",
    "        print(f\"Testing with {len(df_to_process)} episodes out of {len(df)} total episodes\")\n",
    "    else:\n",
    "        df_to_process = df\n",
    "    \n",
    "    for _, row in tqdm(df_to_process.iterrows(), total=len(df_to_process), desc=\"Processing episodes\"):\n",
    "        episode_id = row['episode']\n",
    "        title = row['title']\n",
    "        summary = row['summary']\n",
    "        \n",
    "        # Skip if summary is NaN\n",
    "        if pd.isna(summary):\n",
    "            print(f\"Skipping episode {episode_id} - No summary available\")\n",
    "            continue\n",
    "            \n",
    "        # Create user prompt for this episode\n",
    "        user_prompt = f\"Episode {episode_id}: {title}\\n\\nSummary:\\n{summary}\"\n",
    "        \n",
    "        # Call OpenAI API with retry mechanism for rate limits\n",
    "        max_retries = 3\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"gpt-4o-mini\",  # Using GPT-4o-mini as requested\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": system_prompt},\n",
    "                        {\"role\": \"user\", \"content\": user_prompt}\n",
    "                    ],\n",
    "                    temperature=0.2,  # Lower temperature for more consistent outputs\n",
    "                    response_format={\"type\": \"json_object\"}\n",
    "                )\n",
    "                \n",
    "                # Extract and parse JSON response\n",
    "                response_text = response.choices[0].message.content\n",
    "                episode_data = json.loads(response_text)\n",
    "                \n",
    "                # Ensure sentence field exists (for backward compatibility)\n",
    "                if \"sentence\" not in episode_data:\n",
    "                    episode_data[\"sentence\"] = []\n",
    "                \n",
    "                # Store in ground truth dictionary\n",
    "                ground_truth[str(episode_id)] = episode_data\n",
    "                \n",
    "                # Save intermediate results periodically\n",
    "                if episode_id % 10 == 0:\n",
    "                    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(ground_truth, f, ensure_ascii=False, indent=2)\n",
    "                \n",
    "                # Successful response, break out of retry loop\n",
    "                break\n",
    "                \n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error: Invalid JSON response for episode {episode_id}. Retrying...\")\n",
    "                time.sleep(2)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing episode {episode_id}: {str(e)}\")\n",
    "                if \"rate limit\" in str(e).lower():\n",
    "                    wait_time = (attempt + 1) * 5  # Exponential backoff\n",
    "                    print(f\"Rate limited. Waiting {wait_time} seconds before retry...\")\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    break  # Break on non-rate-limit errors\n",
    "        \n",
    "        # Add a small delay between requests to avoid rate limits\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    # Save final results\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(ground_truth, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"Ground truth data generated and saved to {output_file}\")\n",
    "    return ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4266c0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with 3 episodes out of 444 total episodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:08<00:00,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth data generated and saved to podcast_ground_truth.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('podcast_data.csv')\n",
    "    \n",
    "# Generate ground truth (using environment variable for API key)\n",
    "ground_truth = generate_ground_truth(df, max_episodes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e1f20d5-9dd1-4012-85c1-b634eea054a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with 3 episodes out of 444 total episodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:10<00:00,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth data generated and saved to podcast_ground_truth.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ground_truth = generate_ground_truth(df, max_episodes=3, sample_random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14187285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'299': {'sentence': ['這集的主題圍繞著最近的高溫，大家都在討論如何應對這種酷熱的天氣。',\n",
       "   '主持人提到了一個有趣的概念，叫做冷氣糾察隊，專門檢查別人開冷氣的情況。',\n",
       "   '還有提到一種特別的T-shirt，叫做結晶T-shirt，聽起來很酷。',\n",
       "   '節目中也聊到一些人對於外觀衛生的看法，像是留指甲的問題。',\n",
       "   '整體來說，這集充滿了對於夏天的幽默和生活小觀察。']},\n",
       " '352': {'sentence': ['這集聊到月月陪爸媽參加同學會的趣事，讓我想到自己也有類似的經歷。',\n",
       "   '何媽提到她年輕時的故事，讓我覺得她的生活經歷真的很有趣。',\n",
       "   '倫分享了他參加國小同學會的感受，讓我想起那些熟悉卻又陌生的同學。',\n",
       "   '節目中還提到蔥油餅阿伯的故事，讓我忍不住想流口水。',\n",
       "   '誠誠的家人聚會也很有意思，親戚們的話讓我想起自己家裡的搞笑瞬間。']},\n",
       " '103': {'sentence': ['這集聊到了幸福的定義，大家都覺得幸福有點沉重，不知道該怎麼形容。',\n",
       "   '誠爸從小就知道誠誠是個抓不住的孩子，誠老婆還說不要浪費錢求婚，真是有趣。',\n",
       "   '計程車司機聽到他們的對話後，提醒年輕人要自己決定，爽最重要。',\n",
       "   '他們也討論了工作和創業的不同，工作不需要熱情，但創業就得有了。',\n",
       "   '最後，家倫分享了對未來家庭的想像，覺得建立家庭比登太空還要遙遠。']}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8984daba-d3ba-42a8-8a53-7f267474c9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'312': {'sentence': ['這一集的主題圍繞著新生宿舍的入住須知，提供了實用的建議和注意事項。',\n",
       "   '小何分享了他在宿舍入住初期的趣事，包括看玫瑰之夜和鬼壓床的經歷。',\n",
       "   '節目中提到了一些宿舍生活中的尷尬時刻，例如聽到廁所的尿尿聲和馬桶漏水的問題。',\n",
       "   '打手槍的話題也被提及，讓聽眾感受到宿舍生活的真實與幽默。',\n",
       "   '整集節目充滿了輕鬆的氛圍，讓新生們對宿舍生活有更深入的了解。']},\n",
       " '111': {'sentence': ['這集節目討論了各種泡麵的煮法和搭配，特別是維力炸醬麵的獨特吃法。',\n",
       "   '主持人分享了游泳課後吃泡麵的幸福感，並提到阿公釣魚的回憶。',\n",
       "   '節目中提到的客家文化和方言讓聽眾感受到台灣的多元文化。',\n",
       "   '還有關於遠距離戀愛的趣事，分享了在疫情期間與女友一起玩遊戲的經歷。',\n",
       "   '最後，節目也提到了一些漫畫和動畫作品，並討論了角色設定的合理性。']},\n",
       " '323': {'sentence': ['這一集探討了離職的原因以及在職場中面對的挑戰。',\n",
       "   '節目中提到藍亦明的哥哥是一位資優生，這引發了對家庭期望的討論。',\n",
       "   '藍亦明分享了自己小時候收到的情書，讓人感受到青春的懷舊情懷。',\n",
       "   '節目中有提到如何在關係中找到合適的對象，強調磨合的重要性。',\n",
       "   '藍亦明也分享了整鼻的過程，讓聽眾了解這個話題的不同面向。']}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31efdfde-a777-4f27-88d6-376169cde0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['這一集的主題圍繞著新生宿舍的入住須知，提供了實用的建議和注意事項。',\n",
       " '小何分享了他在宿舍入住初期的趣事，包括看玫瑰之夜和鬼壓床的經歷。',\n",
       " '節目中提到了一些宿舍生活中的尷尬時刻，例如聽到廁所的尿尿聲和馬桶漏水的問題。',\n",
       " '打手槍的話題也被提及，讓聽眾感受到宿舍生活的真實與幽默。',\n",
       " '整集節目充滿了輕鬆的氛圍，讓新生們對宿舍生活有更深入的了解。']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth['312']['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f1c782b-1337-4302-ad6f-f93b072ff506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:   1%|█▊                                                                                                                                                                  | 5/444 [00:19<26:20,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 6 - No summary available\n",
      "Skipping episode 7 - No summary available\n",
      "Skipping episode 8 - No summary available\n",
      "Skipping episode 9 - No summary available\n",
      "Skipping episode 10 - No summary available\n",
      "Skipping episode 11 - No summary available\n",
      "Skipping episode 12 - No summary available\n",
      "Skipping episode 13 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  14%|███████████████████████▏                                                                                                                                           | 63/444 [03:33<23:41,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 64 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  33%|████████████████████████████████████████████████████▉                                                                                                             | 145/444 [08:44<21:13,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 146 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  50%|████████████████████████████████████████████████████████████████████████████████▋                                                                                 | 221/444 [13:15<14:02,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 222 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  51%|██████████████████████████████████████████████████████████████████████████████████                                                                                | 225/444 [13:30<15:51,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 226 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  51%|███████████████████████████████████████████████████████████████████████████████████▏                                                                              | 228/444 [13:38<13:09,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 229 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  56%|███████████████████████████████████████████████████████████████████████████████████████████▏                                                                      | 250/444 [15:03<14:08,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 251 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  59%|███████████████████████████████████████████████████████████████████████████████████████████████▌                                                                  | 262/444 [15:45<10:07,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 263 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  60%|█████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                | 268/444 [16:01<08:42,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 269 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  61%|██████████████████████████████████████████████████████████████████████████████████████████████████▌                                                               | 270/444 [16:03<06:30,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 271 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  62%|████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                             | 275/444 [16:19<08:45,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 276 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  64%|███████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                          | 283/444 [16:49<11:09,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 284 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                    | 300/444 [17:51<10:13,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 301 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                             | 320/444 [18:55<06:20,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 321 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                           | 325/444 [19:16<08:11,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 326 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  81%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                              | 361/444 [21:37<05:02,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 362 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                             | 364/444 [21:44<03:49,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 365 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 375/444 [22:19<03:53,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 376 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  87%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                     | 385/444 [22:54<03:20,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 386 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                | 400/444 [23:47<02:52,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 401 - No summary available\n",
      "Skipping episode 402 - No summary available\n",
      "Skipping episode 403 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍              | 404/444 [23:50<01:19,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 405 - No summary available\n",
      "Skipping episode 406 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌             | 407/444 [23:55<01:06,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 408 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎| 442/444 [26:24<00:07,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 443 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 444/444 [26:27<00:00,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth data generated and saved to podcast_ground_truth.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ground_truth = generate_ground_truth(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27a9673f-0248-41c1-aa78-d9d0398bae9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': ['這集節目聊到了一個很有趣的話題，就是內衣的選擇和穿著。',\n",
       "  '主持人分享了他們對於內衣品牌的看法，還有一些搞笑的經歷。',\n",
       "  '有聽眾提到過去穿錯內衣的尷尬故事，讓大家都忍不住笑了。',\n",
       "  '這集也探討了內衣對於自信心的影響，真的很值得思考。',\n",
       "  '最後，主持人還給了大家一些選擇內衣的小建議，讓人聽了很有收穫。']}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth['400']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4a1ba79-2c24-40eb-8c65-00e7b945fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_topic(df, output_file='podcast_topic.json', api_key=None, max_episodes=None, sample_random=False):\n",
    "    \"\"\"\n",
    "    \n",
    "    Args:\n",
    "        df: Pandas DataFrame containing podcast episode data with 'episode', 'title', and 'summary' columns\n",
    "        output_file: Path to save the ground truth data as JSON\n",
    "        api_key: OpenAI API key (will use environment variable if None)\n",
    "        max_episodes: Maximum number of episodes to process (useful for testing with fewer episodes)\n",
    "        sample_random: If True and max_episodes is set, randomly sample episodes instead of taking first few\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing ground truth data\n",
    "    \"\"\"\n",
    "    # Initialize OpenAI client\n",
    "    if api_key is None:\n",
    "        api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "        if api_key is None:\n",
    "            raise ValueError(\"OpenAI API key not found. Please provide it as an argument or set the OPENAI_API_KEY environment variable.\")\n",
    "    \n",
    "    client = OpenAI(api_key=api_key)\n",
    "    \n",
    "    system_prompt = \"\"\"你是一位知道台灣Podcast「通勤第一品牌」(Commute For Me)的聽眾，熟悉台灣文化和用語。\n",
    "你將獲得「通勤第一品牌」(Commute For Me) podcast的標題和內容摘要。\n",
    "你的任務是：\n",
    "1. 識別該集節目中討論的10~20個關鍵主題或句子\n",
    "\n",
    "輸出格式應為有效的JSON，格式如下：\n",
    "'topic': [\"topic1\", \"topic2\", ..., \"topic20\"]\n",
    "\"\"\"\n",
    "\n",
    "    # Process each episode\n",
    "    podcast_topic = {}\n",
    "    \n",
    "    # Limit the number of episodes if specified\n",
    "    if max_episodes is not None:\n",
    "        if sample_random:\n",
    "            df_to_process = df.sample(min(max_episodes, len(df)))\n",
    "        else:\n",
    "            df_to_process = df.head(max_episodes)\n",
    "        print(f\"Testing with {len(df_to_process)} episodes out of {len(df)} total episodes\")\n",
    "    else:\n",
    "        df_to_process = df\n",
    "    \n",
    "    for _, row in tqdm(df_to_process.iterrows(), total=len(df_to_process), desc=\"Processing episodes\"):\n",
    "        episode_id = row['episode']\n",
    "        title = row['title']\n",
    "        summary = row['summary']\n",
    "        if pd.isnull(row['song_recommendation']):\n",
    "            song = 'null'\n",
    "        else:\n",
    "            song = row['song_recommendation']\n",
    "        \n",
    "        # Skip if summary is NaN\n",
    "        if pd.isna(summary):\n",
    "            print(f\"Skipping episode {episode_id} - No summary available\")\n",
    "            continue\n",
    "            \n",
    "        # Create user prompt for this episode\n",
    "        user_prompt = f\"Episode {episode_id}: {title}\\n\\nSummary:\\n{summary}\"\n",
    "        \n",
    "        # Call OpenAI API with retry mechanism for rate limits\n",
    "        max_retries = 3\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"gpt-4o-mini\",  # Using GPT-4o-mini as requested\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": system_prompt},\n",
    "                        {\"role\": \"user\", \"content\": user_prompt}\n",
    "                    ],\n",
    "                    temperature=0.2,  # Lower temperature for more consistent outputs\n",
    "                    response_format={\"type\": \"json_object\"}\n",
    "                )\n",
    "                \n",
    "                # Extract and parse JSON response\n",
    "                response_text = response.choices[0].message.content\n",
    "                episode_data = json.loads(response_text)\n",
    "                \n",
    "                # Ensure sentence field exists (for backward compatibility)\n",
    "                if \"topic\" not in episode_data:\n",
    "                    episode_data[\"topic\"] = []\n",
    "\n",
    "                episode_data[\"song\"] = song\n",
    "                \n",
    "                # Store in ground truth dictionary\n",
    "                podcast_topic[str(episode_id)] = episode_data\n",
    "                \n",
    "                # Save intermediate results periodically\n",
    "                if episode_id % 10 == 0:\n",
    "                    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(podcast_topic, f, ensure_ascii=False, indent=2)\n",
    "                \n",
    "                # Successful response, break out of retry loop\n",
    "                break\n",
    "                \n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error: Invalid JSON response for episode {episode_id}. Retrying...\")\n",
    "                time.sleep(2)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing episode {episode_id}: {str(e)}\")\n",
    "                if \"rate limit\" in str(e).lower():\n",
    "                    wait_time = (attempt + 1) * 5  # Exponential backoff\n",
    "                    print(f\"Rate limited. Waiting {wait_time} seconds before retry...\")\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    break  # Break on non-rate-limit errors\n",
    "        \n",
    "        # Add a small delay between requests to avoid rate limits\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    # Save final results\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(podcast_topic, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"Process data generated and saved to {output_file}\")\n",
    "    return podcast_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d03bce8-9175-4890-87b7-4926f91b7a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with 3 episodes out of 444 total episodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes: 100%|████████████████████████████████████████████████████| 3/3 [00:11<00:00,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process data generated and saved to podcast_topic.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('podcast_data.csv')\n",
    "    \n",
    "# Generate ground truth (using environment variable for API key)\n",
    "podcast_topic = generate_topic(df, max_episodes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d7ac0ff-6aef-4c96-9cfb-7fa441f57590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'topic': ['NMSL的起源',\n",
       "   'CS遊戲文化',\n",
       "   '丹麥二線玩家',\n",
       "   'envy團體',\n",
       "   'NMSL的含義',\n",
       "   '刺青文化',\n",
       "   '中泰twitter大戰',\n",
       "   '避敏感詞的用法',\n",
       "   '台灣的委婉表達',\n",
       "   '吳淑珍的網路搜尋',\n",
       "   '馬鶴凌的提及',\n",
       "   '人類集體淺意識',\n",
       "   '文字獄的討論',\n",
       "   '5000年的傳統',\n",
       "   '白色恐怖的歷史',\n",
       "   '誠誠的遊戲名字',\n",
       "   '手肘走路的練習',\n",
       "   '社會政治的隱喻',\n",
       "   '文化認同的探討'],\n",
       "  'song': nan},\n",
       " '2': {'topic': ['多人運動',\n",
       "   '偷情',\n",
       "   'VR做愛',\n",
       "   '通姦罪',\n",
       "   '公投',\n",
       "   '性成癮',\n",
       "   '開放性關係',\n",
       "   '羞辱感',\n",
       "   '身心分離派',\n",
       "   '空幹影片',\n",
       "   '母系社會',\n",
       "   '出軌外遇',\n",
       "   '應變能力',\n",
       "   '誠實應對',\n",
       "   '名人稅',\n",
       "   '林俊傑',\n",
       "   '台獨',\n",
       "   '羅志祥',\n",
       "   '柯粉',\n",
       "   '和解'],\n",
       "  'song': nan},\n",
       " '3': {'topic': ['清大人社學費爭論',\n",
       "   '宿舍費不退',\n",
       "   '綽號文化',\n",
       "   '條直性格',\n",
       "   '自我介紹方式',\n",
       "   '連戰的父親身份',\n",
       "   '綽號的創造與使用',\n",
       "   '李敖語錄',\n",
       "   '家庭暴力話題',\n",
       "   '性騷擾事件',\n",
       "   '社交壓力',\n",
       "   '父母對工作升遷的影響',\n",
       "   '支持民眾黨',\n",
       "   '西瓜挑戰',\n",
       "   '家庭背景與努力的關係',\n",
       "   '搞笑的原則',\n",
       "   '社會期待與個人努力',\n",
       "   '韓流影響政治',\n",
       "   '印象管理'],\n",
       "  'song': nan}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "podcast_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd2e2b8c-72b9-498b-af3d-227da93d73e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with 5 episodes out of 444 total episodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes: 100%|████████████████████████████████████████████████████| 5/5 [00:18<00:00,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process data generated and saved to podcast_topic.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "podcast_topic = generate_topic(df, max_episodes=5, sample_random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c5bbe03-580f-4e32-9228-e9cda1aa7bde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'203': {'topic': ['威滅的廣告劇',\n",
       "   '何ㄟ女友和維力炸醬麵',\n",
       "   '泡麵冷暴力',\n",
       "   '咖啡盤子的用途',\n",
       "   '奶茶機的回憶',\n",
       "   '台大學習的理論',\n",
       "   '整鰭器的使用',\n",
       "   '電影私法爭鋒',\n",
       "   '吳斐莉代言的鞋子',\n",
       "   '電影阿凡達的評價',\n",
       "   '品味的懷疑',\n",
       "   '重看Star Trek 2009',\n",
       "   '小何的故事',\n",
       "   '網頁瀏覽器的分類',\n",
       "   '情緒管理',\n",
       "   '台裔醫師的勇氣',\n",
       "   '釣魚行為的影響',\n",
       "   '負面情緒的勾動'],\n",
       "  'song': nan},\n",
       " '281': {'topic': ['夢境',\n",
       "   '張菲',\n",
       "   '睡袍',\n",
       "   '乃哥家',\n",
       "   '採訪',\n",
       "   '打麻將',\n",
       "   '成功學',\n",
       "   '筆記',\n",
       "   '超慢跑',\n",
       "   '披薩',\n",
       "   '減肥學',\n",
       "   '減肥失敗',\n",
       "   '成功學的可信度',\n",
       "   '邊做邊吃',\n",
       "   '生活方式',\n",
       "   '幽默',\n",
       "   '文化',\n",
       "   '台灣名人',\n",
       "   '休閒活動'],\n",
       "  'song': '超時空要塞'},\n",
       " '41': {'topic': ['春艷的合作經歷',\n",
       "   '第一次拿到的報酬',\n",
       "   '黑貓宅急便的工作經歷',\n",
       "   '家庭背景與佛法信仰',\n",
       "   '冥想在監獄生活中的作用',\n",
       "   '集體意志的重要性',\n",
       "   '夜生活的享受與失控',\n",
       "   '對於他人觀點的看法',\n",
       "   '慾望的空虛',\n",
       "   '夜生活中的抓馬事件',\n",
       "   '人生的需求與想要的區分',\n",
       "   '交大八社的烤香腸',\n",
       "   '音樂與情感的連結',\n",
       "   '夜貓組的代言歌',\n",
       "   '社交與人際關係的挑戰',\n",
       "   '對於生活中發生事情的接受',\n",
       "   '倫的學習與生活態度',\n",
       "   '春艷的音樂創作背景',\n",
       "   '夜生活的社會文化影響',\n",
       "   '對於失控的恐懼與接受'],\n",
       "  'song': '/'},\n",
       " '152': {'topic': ['倫迷看治療蹄底皮膚指甲病的影片',\n",
       "   '何ㄟ開始節食',\n",
       "   '168斷食法',\n",
       "   '186斷食法',\n",
       "   '何特愛小熊軟糖',\n",
       "   '哈根達斯冰淇淋',\n",
       "   '倫是馬鈴薯狂粉',\n",
       "   '薯餅蛋吐司',\n",
       "   '早餐店傑克阿姨',\n",
       "   '誠愛吃阿英煎的荷包蛋',\n",
       "   '喜歡吃濃郁的東西',\n",
       "   '海膽',\n",
       "   '臭臭的起司',\n",
       "   '家倫飲料不管什麼時候都點正常冰',\n",
       "   '從來不點少冰',\n",
       "   '家倫健身教練',\n",
       "   '掉到地上三秒理論',\n",
       "   '複雜的慾望',\n",
       "   '執念',\n",
       "   'apple tv上買4k修復版電影',\n",
       "   '電影李安父親三部曲'],\n",
       "  'song': '鼓擊樂團——One Way Trigger'},\n",
       " '430': {'topic': ['何電腦C槽壞掉',\n",
       "   '系統碟壞掉',\n",
       "   '小影片備份',\n",
       "   '前柯主席雙關',\n",
       "   '小草列出友白KOL',\n",
       "   '台灣通勤第一品牌排名',\n",
       "   '賴清德違建',\n",
       "   '台灣言論自由',\n",
       "   '李毅誠反串',\n",
       "   '何欸聽不懂反串',\n",
       "   '隱士下鋤田文本分析',\n",
       "   '土城詩人',\n",
       "   '五言絕句創作',\n",
       "   '詞選寫炫耀',\n",
       "   '中文系期末考',\n",
       "   '老師評語進步明顯',\n",
       "   '反串識別度低',\n",
       "   '棕櫚樹發音',\n",
       "   '自詡發音',\n",
       "   '踉蹌發音'],\n",
       "  'song': \"逞誠：B'z - 今夜月の見える丘に\\n看日劇「美麗人生 (ビューティフルライフ)」，推主題曲\"}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "podcast_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76bc6d97-eeb1-4a50-86f2-c187a3a4962e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:   1%|▌                                                 | 5/444 [00:17<26:21,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 6 - No summary available\n",
      "Skipping episode 7 - No summary available\n",
      "Skipping episode 8 - No summary available\n",
      "Skipping episode 9 - No summary available\n",
      "Skipping episode 10 - No summary available\n",
      "Skipping episode 11 - No summary available\n",
      "Skipping episode 12 - No summary available\n",
      "Skipping episode 13 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  14%|██████▉                                          | 63/444 [03:57<25:34,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 64 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  33%|███████████████▋                                | 145/444 [09:25<19:37,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 146 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  50%|███████████████████████▉                        | 221/444 [14:31<13:26,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 222 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  51%|████████████████████████▎                       | 225/444 [14:42<11:51,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 226 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  51%|████████████████████████▋                       | 228/444 [14:50<10:57,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 229 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  56%|███████████████████████████                     | 250/444 [16:16<16:25,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 251 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  59%|████████████████████████████▎                   | 262/444 [16:58<11:03,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 263 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  60%|████████████████████████████▉                   | 268/444 [17:19<10:53,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 269 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  61%|█████████████████████████████▏                  | 270/444 [17:22<08:01,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 271 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  62%|█████████████████████████████▋                  | 275/444 [17:40<10:35,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 276 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  64%|██████████████████████████████▌                 | 283/444 [18:01<08:09,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 284 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  68%|████████████████████████████████▍               | 300/444 [19:11<09:51,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 301 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  72%|██████████████████████████████████▌             | 320/444 [20:24<07:28,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 321 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  73%|███████████████████████████████████▏            | 325/444 [20:41<08:12,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 326 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  81%|███████████████████████████████████████         | 361/444 [23:02<05:15,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 362 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  82%|███████████████████████████████████████▎        | 364/444 [23:07<03:36,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 365 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  84%|████████████████████████████████████████▌       | 375/444 [23:50<04:47,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 376 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  87%|█████████████████████████████████████████▌      | 385/444 [24:24<03:54,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 386 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  90%|███████████████████████████████████████████▏    | 400/444 [25:21<02:36,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 401 - No summary available\n",
      "Skipping episode 402 - No summary available\n",
      "Skipping episode 403 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  91%|███████████████████████████████████████████▋    | 404/444 [25:24<01:13,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 405 - No summary available\n",
      "Skipping episode 406 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  92%|████████████████████████████████████████████    | 407/444 [25:28<00:56,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 408 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes: 100%|███████████████████████████████████████████████▊| 442/444 [27:48<00:07,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping episode 443 - No summary available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes: 100%|████████████████████████████████████████████████| 444/444 [27:51<00:00,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process data generated and saved to podcast_topic.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "podcast_topic = generate_topic(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbd2692-a0b3-40c3-a7a9-a64362131b09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
